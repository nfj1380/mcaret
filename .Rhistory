for (response_value in response_names_filt) {
response_data <- subset(G_target_data_final_df, response == response_value)
target_data_final_df <-  response_data %>%
slice_max(order_by = sd_value, n = local_top_var)
plot <- ggplot(target_data_final_df, aes(x = sd_value, y = reorder(var, sd_value))) +
geom_boxplot() +
theme_bw() +
labs(x = "Importance", y = response_value) +
theme(
axis.title.x = element_text(size = 8),
axis.title.y = element_text(size = 8)
)
plot_list[[response_value]] <- plot
}
p2 <- arrangeGrob(grobs = plot_list, plot = FALSE)
combined_plot <- plot_grid(p1, p2, rel_heights = c(1, 0.5), labels = "auto")
#for a taxa of interest
if(!is.null(taxa)){
# Filter the data for the provided taxa
target_data <- vi_table %>% dplyr::filter(response == taxa)
# Calculate the mean importance of each variable
target_data_avg <- target_data %>%
dplyr::group_by(var) %>%
dplyr::summarise(mean_imp = mean(sd_value)) %>%
ungroup()
# Get the top variables
top_vars <- head(target_data_avg[order(-target_data_avg$mean_imp), ], local_top_var)
# Filter the data to include only the top variables
target_data_final_df <- target_data %>% dplyr::filter(var %in% top_vars$var)
# Create the boxplot for the target
p3 <- ggplot(target_data_final_df, aes(x = sd_value, y = reorder(var, sd_value))) +
geom_boxplot() +
theme_bw() +
labs(x = "Importance", y = taxa) +
scale_y_discrete(label = abbreviate) +
theme(
axis.title.x = element_text(size = 8),
axis.title.y = element_text(size = 8)
)
#publication ready plot
combined_plot <- plot_grid(p1, p2,p3, rel_heights = c(1, 0.5), labels = "auto")
}
#for bootstraps
if (!is.null(mrBootstrap_obj)) {
n_response <- ncol(Y)
complete_df <- cbind(Y, X)
n_data <- ncol(complete_df)
bind_rows_by_name <- function(list_obj, object_name) {
filtered_list <- list_obj[names(list_obj) %in% object_name]
bind_rows(filtered_list)
}
internal_fit_function <- function(i) {
object_name <- names(complete_df[i])
combined_list <- list()  # Create an empty list to store combined objects
for (j in 1:n_response) {
combined_object <- map_dfr(mrBootstrap_obj[[j]], bind_rows_by_name, object_name)
if (nrow(combined_object) > 0) {
combined_objfinal <- combined_object #this makes sure it doesnt save the duplicates
combined_list[[j]] <-  combined_objfinal  # Append the combined object to the list
}
}
combined_df <- do.call(rbind, combined_list)  # Convert the list to a data frame
return(combined_df)
}
pd_list <- future_lapply(seq_len(n_data), internal_fit_function, future.seed = TRUE)
vi_list <- list()  # Create an empty list to store the plots
for (i in seq_along(pd_list)) {
#extract data for each variable in the models
df <-  pd_list[[i]]
#calculate the standard deviation of each bootstrap for each taxa
result <- df %>%
dplyr::group_by(response, bootstrap) %>%
summarise(sd_value = sd(value))%>%
ungroup()
#add the variables names back in
df_names <- rep(names(df[1]), nrow(result))
result_update <- cbind(result, var=df_names)
vi_list[[i]] <- result_update
}
vi_df <- do.call(rbind, vi_list)
#NB#could have a groupCv argument here
G_target_data_avg <- vi_df %>%
dplyr::group_by(var) %>%
summarise(mean_imp = mean(sd_value))
# Create the boxplot for the target
#get top variables
G_top_vars <- head(G_target_data_avg[order(-G_target_data_avg$mean_imp), ], global_top_var)
G_target_data_final_df <- vi_df %>%
dplyr::filter(var %in% G_top_vars$var)
#plot overall importance
p1 <- ggplot(G_target_data_final_df, aes(y=reorder(var,sd_value), x=sd_value))+
geom_boxplot()+
theme_bw()+
labs(x="Importance", y="Features")+
theme(
axis.title.x = element_text(size = 8),  # Adjust the size as needed
axis.title.y = element_text(size = 8)
)
#grid.arrange(p1)
#boxplots for each individual predictor
# Filter the data based on the threshold and calculate mean values for each target
filtered_data <-  vi_df %>%
dplyr::group_by(response) %>%
summarise(sd_value = mean(sd_value)) %>%
right_join(ModelPerf[[1]], by = join_by(response)) %>%
filter(roc_AUC > threshold) %>%
ungroup()
# Create a list to store the plots
plot_list <- list()
# Generate boxplots for each target
for (k in 1:nrow(filtered_data)) {
target <- filtered_data$response[k]###
# Filter the data for the current target
target_data <-  vi_df %>%
filter(response == {{target}})
target_data_avg <- target_data %>%
dplyr::group_by(var) %>%
dplyr::summarise(mean_imp = mean(sd_value)) %>%
ungroup()
# Create the boxplot for the target
#get top variables
top_vars <- head(target_data_avg[order(-target_data_avg$mean_imp), ], local_top_var)
target_data_final_df <- target_data %>%
dplyr::filter(var %in% top_vars$var)
plot <- ggplot(target_data_final_df, aes(x = sd_value, y = reorder(var, sd_value))) +
geom_boxplot() +
theme_bw()+
labs(x="Importance", y=target)+
scale_y_discrete(label=abbreviate)+
theme(
axis.title.x = element_text(size = 8),  # Adjust the size as needed
axis.title.y = element_text(size = 8)
)
# Add the plot to the list
plot_list[[k]] <- plot
}
# Arrange and display the plots in a grid
#p2 <- grid.arrange(grobs = plot_list, plot = FALSE)
p2 <- arrangeGrob(grobs = plot_list, plot = FALSE)
#publication ready plot
combined_plot <- plot_grid(p1, p2, rel_heights = c(1, 0.5), labels = "auto")
#for a taxa of interest
if(!is.null(taxa)){
# Filter the data for the provided taxa
target_data <- vi_df %>% filter(response == taxa)
# Calculate the mean importance of each variable
target_data_avg <- target_data %>%
dplyr::group_by(var) %>%
summarise(mean_imp = mean(sd_value)) %>%
ungroup()
# Get the top variables
top_vars <- head(target_data_avg[order(-target_data_avg$mean_imp), ], local_top_var)
# Filter the data to include only the top variables
target_data_final_df <- target_data %>% filter(var %in% top_vars$var)
# Create the boxplot for the target
p3 <- ggplot(target_data_final_df, aes(x = sd_value, y = reorder(var, sd_value))) +
geom_boxplot() +
theme_bw() +
labs(x = "Importance", y = taxa) +
scale_y_discrete(label = abbreviate) +
theme(
axis.title.x = element_text(size = 8),
axis.title.y = element_text(size = 8)
)
#publication ready plot
combined_plot <- plot_grid(p1, p2,p3, rel_heights = c(1, 0.5), labels = "auto")
}
}
#------------------------------------------------------------------
#Importance PCA plot. Responses with similar importance scores group together
#------------------------------------------------------------------
if (plot.pca) {
vi_table_wide <- vi_table %>%
pivot_wider(
id_cols = 'var',
names_from = "response",
values_from = "sd_value") %>%
column_to_rownames('var') %>%
mutate(across(everything(), ~replace(., is.na(.), mean(., na.rm = TRUE))))#or impute with code below
# #X1 will have missing values. This algorithm will impute them with no impact on the pca
# if(!is.null(X1)) {
#
#   ## First the number of components has to be chosen
#   ## (for the reconstruction step)
#
# nb <- estim_ncpPCA(vi_table_wide,ncp.max=4)
#
# ## Multiple Imputation
# vi_table_wide_t <- missMDA::MIPCA( vi_table_wide, ncp = 1)
#
# #get the data
# vi_table_wide <- vi_table_wide_t$res.imputePCA
#
# }
#
# else {
#
#   #keep the data as is otherwise
#   vi_table_wide <- vi_table_wide
# }
#seems like it doesn't make too much difference
a.pca <-  t(vi_table_wide) %>%
prcomp() # do PCA
print('here')
#-----------------------------------------------------------------------------------------
#outlier detection
uscores <- a.pca$x %>%
as.data.frame()
outL <- apply(uscores, 2, function(x) which( (abs(x - median(x)) / mad(x)) > 6 ))
#-----------------------------------------------------------------------------------------
pca_val <-  a.pca  %>%
tidy(matrix = "eigenvalues")
trans <- t(vi_table_wide)
p3 <- a.pca %>%
augment(trans) %>%
ggplot(aes(.fittedPC1, .fittedPC2)) +
geom_point() +
ggrepel::geom_label_repel(aes(label = rownames(trans)),
box.padding   = 0.35,
point.padding = 0.5,
label.size = 0.1,
segment.color = 'grey50') +
theme_bw()
p4 <- a.pca %>%
tidy(matrix = "eigenvalues") %>%
ggplot(aes(PC, percent)) +
geom_col(fill = "#56B4E9", alpha = 0.8) +
scale_x_continuous(breaks = 1:9) +
scale_y_continuous(
labels = scales::percent_format(),
expand = expansion(mult = c(0, 0.01))
) +
theme_bw()
combined_plot_PCA <- plot_grid( p3, p4, rel_heights = c(1, 0.5), labels = "auto")
}
else {
combined_plot_PCA <- NULL
outLiers  <- NULL
pca_val <- NULL
scores <- NULL
}
return(list(vi_df,vi_table_wide, combined_plot,  combined_plot_PCA, outLiers=outL,  pca_val=pca_val, scores=uscores))
}
#calculate variable importance
#still got a bug here to do with the PCA
VI <- mrvip(yhats,  mrBootstrap_obj = NULL,
X = X,
Y = Y,
mode = 'classification',
threshold = 0.0,
global_top_var = 1,
local_top_var = 1,
ModelPerf = ModelPerf,
plot.pca =F
)
#calculate variable importance
#still got a bug here to do with the PCA
VI <- mrvip(yhats,  mrBootstrap_obj = NULL,
X = X,
Y = Y,
mode = 'classification',
threshold = 0.0,
global_top_var = 1,
local_top_var = 1,
ModelPerf = ModelPerf,
plot.pca =T
)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
# Sample data frames (replace these with your actual data frames)
df1 <- data.frame(ID = 1:5, Value = letters[1:5])
df2 <- data.frame(ID = 1:5, Value = LETTERS[1:5])
df3 <- data.frame(ID = 1:5, Value = month.name[1:5])
#we will add this as a mrIML error in the next version.
# Function to check if row IDs match across data frames
check_row_ids <- function(df_list) {
# Extract row IDs for each data frame
row_ids <- df_list %>%
map(rownames)
# Check if row IDs match across all data frames
if (all(row_ids[[1]] == row_ids)) {
cat("Row IDs match across all data frames.\n")
return(TRUE)
} else {
cat("Row IDs do not match between data frames.\n")
return(FALSE)
}
}
# Usage
data_frames <- list(df1, df2, df3)
check_row_ids(data_frames)
yhats_rf <- mrIMLpredicts(X=X,Y=Y, Model=model_rf, balance_data='no', mode='classification',k=5,  tune_grid_size=5,
seed = 123, racing=T ) ## in MrTidymodels. Balanced data= up upsamples and down downsampled to create a balanced set
#make sure you have installed devtools previously.
#Install the most uptodate version from github
#if (!requireNamespace("devtools", quietly = TRUE))
# install.packages("devtools")
#   devtools:: install_github('nfj1380/mrIML')
library(mrIML)
#other package we need:
pacman:: p_load(
vip, tidymodels, randomForest, caret, gbm,
tidyverse, parallel, doParallel, themis, viridis,
janitor, hrbrthemes, xgboost, vegan, flashlight,
ggrepel, iml, plyr, future.apply, gridExtra, cowplot, hstats
)
#library(LEA)
#if (!requireNamespace("BiocManager", quietly = TRUE))
# install.packages("BiocManager") #LEA requires Biocmanager
#load SNP data
#Responsedata)
#if you have a plink dataset you can load it in to our pipeline with the following:
#snps <- readSnpsPed("snp.ped", "snp.map") #NAs in data and interpolated as the mode.
#landscape and host features (or predictors). Note that samples must be rows.
str(Features)
# # remove NAs from the feature/predictor data.
FeaturesnoNA<-Features[complete.cases(Features), ]
X <- FeaturesnoNA #for simplicity
#for more efficent testing for interactions (more variables more interacting pairs)
X <- FeaturesnoNA[c(1:3)] #three features only
#Optional: Filter rare/common SNPs or species. Retaining minor allelle frequncies >0.1 and removing common allelles (occur>0.9)
fData <- filterRareCommon (Responsedata, lower=0.4, higher=0.7)
Y <- fData #for simplicity when comparing
#another option at this stage is to filter response that are strongly correlated with each other.
#df2 <- cor(X) #find correlations
#hc <-  findCorrelation(df2, cutoff=0.5) # put any value as a "cutoff".
#hc <-  sort(hc)
#X <-  X[,-c(hc)] #
model_rf <-
rand_forest(trees = 100, mode = "classification", mtry = tune(), min_n = tune()) %>% #100 trees are set for brevity. Aim to start with 1000
set_engine("randomForest")
#we are tuning mtry and min_n
#set up parallel processing. If you don't add the code below it will still work but just on one core.
## detectCores() #check how many cores you have available. We suggest keeping one core free for internet browsing etc.
cl <- parallel::makeCluster(4)
plan(cluster, workers=cl)
yhats_rf <- mrIMLpredicts(X=X,Y=Y, Model=model_rf, balance_data='no', mode='classification',k=5,  tune_grid_size=5,
seed = 123, racing=T ) ## in MrTidymodels. Balanced data= up upsamples and down downsampled to create a balanced set
yhats_rf <- mrIMLpredicts(X=X,Y=Y, Model=model_rf, balance_data='no', mode='classification',k=5,  tune_grid_size=5,
seed = 123, racing=F ) ## in MrTidymodels. Balanced data= up upsamples and down downsampled to create a balanced set
# save the model
#save(yhats, file='rf_model')
library(mrIML)
# to load
library(vip); library(tidymodels);
library(randomForest); library(caret);
library(gbm); library(tidyverse);
library(parallel); library(doParallel);
library(themis); library(viridis);
library(janitor); library(hrbrthemes);
library(xgboost); library(vegan);
library(flashlight);library(ggrepel);
library(iml); library(plyr);
library(future.apply)
library(cowplot)
model1 <-
rand_forest(trees = 10, mode = "classification",
mtry = tune(),
min_n = tune()) %>% #100 trees are set for brevity
set_engine("randomForest")
fData <- filterRareCommon (Responsedata,
lower=0.4,
higher=0.7)
data <- fData[1:20]
#Define set of features
fData <- filterRareCommon (Responsedata,
lower=0.4,
higher=0.7)
Y <- fData #For simplicity when comparing
#Define set the outcomes of interest
str(Features)
#Remove NAs from the feature/predictor data.
FeaturesnoNA<-Features[complete.cases(Features), ]
X <- FeaturesnoNA #For simplicity
#For more efficient testing for interactions (more variables more interacting pairs)
X <- FeaturesnoNA[c(1:3)] #Three features only
yhats <- mrIMLpredicts(X=X, #Features/predictors
Y=Y, #Response data
Model=model1, #Specify your model
balance_data='no', #Chose how to balance your data
k=5,
racing = F,
mode='classification', #Chose your mode (classification versus regression)
seed = 120) #Set seed
#Define set of features
fData <- filterRareCommon (Responsedata,
lower=0.4,
higher=0.7)
Y <- fData #For simplicity when comparing
#Define set the outcomes of interest
str(Features)
#Remove NAs from the feature/predictor data.
FeaturesnoNA<-Features[complete.cases(Features), ]
X <- FeaturesnoNA #For simplicity
#For more efficient testing for interactions (more variables more interacting pairs)
X <- FeaturesnoNA[c(1:3)] #Three features only
yhats <- mrIMLpredicts(X=X, #Features/predictors
Y=Y, #Response data
Model=model1, #Specify your model
balance_data='no', #Chose how to balance your data
k=5,
racing = T,
mode='classification', #Chose your mode (classification versus regression)
seed = 120) #Set seed
pacman:: p_load(
vip, tidymodels, randomForest, caret, gbm,
tidyverse, parallel, doParallel, themis, viridis,
janitor, hrbrthemes, xgboost, vegan, flashlight,
ggrepel, iml, plyr, future.apply, gridExtra, cowplot, hstats
)
model1 <-
rand_forest(trees = 10, mode = "classification",
mtry = tune(),
min_n = tune()) %>% #100 trees are set for brevity
set_engine("randomForest")
fData <- filterRareCommon (Responsedata,
lower=0.4,
higher=0.7)
data <- fData[1:20]
Y <- fData #For simplicity when comparing
#Define set the outcomes of interest
str(Features)
#Remove NAs from the feature/predictor data.
FeaturesnoNA<-Features[complete.cases(Features), ]
X <- FeaturesnoNA #For simplicity
#For more efficient testing for interactions (more variables more interacting pairs)
X <- FeaturesnoNA[c(1:3)] #Three features only
yhats_rf <- mrIMLpredicts(X=X,Y=Y,
Model=model_rf, balance_data='no', mode='classification',k=5,  tune_grid_size=5,
seed = 123, racing=F )  #Set seed
model_rf <-
rand_forest(trees = 100, mode = "classification", mtry = tune(), min_n = tune()) %>% #100 trees are set for brevity. Aim to start with 1000
set_engine("randomForest")
Y <- fData #For simplicity when comparing
#Define set the outcomes of interest
str(Features)
#Remove NAs from the feature/predictor data.
FeaturesnoNA<-Features[complete.cases(Features), ]
X <- FeaturesnoNA #For simplicity
#For more efficient testing for interactions (more variables more interacting pairs)
X <- FeaturesnoNA[c(1:3)] #Three features only
yhats_rf <- mrIMLpredicts(X=X,Y=Y,
Model=model_rf, balance_data='no', mode='classification',k=5,  tune_grid_size=5,
seed = 123, racing=F )  #Set seed
ModelPerf <- mrIMLperformance(yhats=yhats,
Model=model1,
Y=Y, mode='classification')
Y <- fData #For simplicity when comparing
#Define set the outcomes of interest
str(Features)
#Remove NAs from the feature/predictor data.
FeaturesnoNA<-Features[complete.cases(Features), ]
X <- FeaturesnoNA #For simplicity
#For more efficient testing for interactions (more variables more interacting pairs)
X <- FeaturesnoNA[c(1:3)] #Three features only
yhats_rf <- mrIMLpredicts(X=X,Y=Y,
Model=model_rf, balance_data='no', mode='classification',k=5,  tune_grid_size=5,
seed = 123, racing=F )  #Set seed
ModelPerf <- mrIMLperformance(yhats=yhats_rf,
Model=model_rf,
Y=Y, mode='classification')
ModelPerf[[1]] #Predictive performance for individual responses
ModelPerf[[2]]#Overall predictive performance. r2 for regression and MCC for classification
VI <- mrvip(yhats_rf, X=X, Y=Y)
bs_impVI <- mrvip(
mrBootstrap_obj = NULL,
yhats = yhats_rf,
X = X,
Y = Y,
mode = 'classification',
threshold = 0.0,
global_top_var = 10,
local_top_var = 5,
taxa = 'pol_132',
ModelPerf = ModelPerf_rf
)
bs_impVI <- mrvip(
mrBootstrap_obj = NULL,
yhats = yhats_rf,
X = X,
Y = Y,
mode = 'classification',
threshold = 0.0,
global_top_var = 10,
local_top_var = 5,
taxa = 'pol_132',
ModelPerf = ModelPerf
)
bs_impVI[[3]] #importance
bs_impVI[[4]] #PCA
flashlightObj <- mrFlashlight(yhats_rf,
X=X,
Y=Y,
response = "single",
index=1,
mode='classification')
#plot prediction scatter for all responses. Gets busy with
plot(light_scatter(flashlightObj,
v = "Forest",
type = "predicted"))
#plots everything on one plot (partial dependency, ALE, scatter)
plot(light_effects(flashlightObj,
v = "Grassland"),
use = "all")
#profileData_pd <- light_profile(flashlightObj,  v = "Grassland")
#mrProfileplot(profileData_pd , sdthresh =0.05) #sdthresh removes responses from the first plot that do not vary with the feature
profileData_ale <- light_profile(flashlightObj,
v = "Grassland",
type = "ale") #accumulated local effects
mrProfileplot(profileData_ale,
sdthresh =0.01)
#the second plot is the cumulative turnover function
