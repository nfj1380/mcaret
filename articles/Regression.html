<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Regression • mrIML</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Regression">
<meta property="og:image" content="">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">


    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">mrIML</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>

  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Common%20errors%20in%20mrIML.html">Common errors in mrIML</a>
    </li>
    <li>
      <a href="../articles/Swine%20biosecurity.html">Swine Biosecurity working example</a>
    </li>
    <li>
      <a href="../articles/Landscape%20genetics%20(classification).html">Classification working example</a>
    </li>
    <li>
      <a href="../articles/Regression.html">Regression working example</a>
    </li>
    <li>
      <a href="../articles/Landscape%20genetics.html">Landscape genetics</a>
    </li>
    <li>
      <a href="../articles/Graphical%20network%20model%20(GNM).html">Graphical network model (GNM)</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/nfj1380/mrIML">
    <span class="fa fa-github"></span>

  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Regression</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/nfj1380/mrIML/blob/master/vignettes/Regression.Rmd"><code>vignettes/Regression.Rmd</code></a></small>
      <div class="hidden name"><code>Regression.Rmd</code></div>

    </div>

    
    
<p>MrIML is a R package allows users to generate and interpret
multi-response models (i.e., joint species distribution models)
leveraging advances in data science and machine learning. MrIML couples
the tidymodel infrastructure developed by Max Kuhn and colleagues with
model agnostic interpretable machine learning tools to gain insights
into multiple response data such as. As such mrIML is flexible and
easily extendable allowing users to construct everything from simple
linear models to tree-based methods for each response using the same
syntax and same way to compare predictive performance. In this vignette
we will guide you through how to apply this package to ecological
genomics problems using the regression functionality of the package.
This data set comes from Fitzpatrick et al 2014 who were examining
adaptive genetic variation in relation to geography and climate
adaptation (current and future) in balsam poplar(Populus balsamifera).
See Ecology Letters, (2014) doi: 10.1111/ele.12376. In this paper they
used the similar gradient forests routine (see Ellis et al 2012
Ecology), and we show that MrIML can not only provide more flexible
model choice and interpretive capabilities, but can derive new insights
into the relationship between climate and genetic variation. Further, we
show that linear models of each loci have slightly greater predictive
performance.</p>
<p>We focus on the adaptive SNP loci from GIGANTEA-5 (GI5) gene that has
known links to stem development, plant circadian clock and light
perception pathway. The data is the proportion of individuals in that
population with that SNP loci.</p>
<div class="section level3">
<h3 id="lets-load-that-data">Lets load that data<a class="anchor" aria-label="anchor" href="#lets-load-that-data"></a>
</h3>
<p>###Parallel processing</p>
<p>MrIML provides uses the flexible future apply functionality to set up
multi-core processing. In the example below, we set up a cluster using 4
cores. If you don’t set up a cluster, the default settings will be used
and the analysis will run sequentially.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># detectCores() #check how many cores you have available. We suggest keeping one core free for internet browsing etc.</span></span>
<span></span>
<span><span class="va">cl</span> <span class="op">&lt;-</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html" class="external-link">makeCluster</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="va">cluster</span>, workers<span class="op">=</span><span class="va">cl</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="running-the-analyis">Running the analyis<a class="anchor" aria-label="anchor" href="#running-the-analyis"></a>
</h3>
<p>Performing the analysis is very similar to our classification
example. Lets start with a constructing a linear model for this data
set. We set Model 1 to a linear regression. See <a href="https://www.tidymodels.org/find/" class="external-link uri">https://www.tidymodels.org/find/</a> for other regression
model options Note that ‘mode’ must be regression and in MrIMLpredicts,
model has to be set to ‘regression’.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_lm</span> <span class="op">&lt;-</span> <span class="co">#model used to generate yhat</span></span>
<span>  <span class="co"># specify that the model is a random forest</span></span>
<span>  <span class="fu">linear_reg</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="co"># select the engine/package that underlies the model</span></span>
<span>  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"lm"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span></span>
<span>  <span class="co"># choose either the continuous regression or binary classification mode</span></span>
<span>  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"regression"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">yhats_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mrIMLpredicts.html">mrIMLpredicts</a></span><span class="op">(</span>X<span class="op">=</span><span class="va">X</span>,</span>
<span>                          Y<span class="op">=</span><span class="va">Y</span>,</span>
<span>                          X1<span class="op">=</span><span class="cn">NULL</span>,</span>
<span>                          Model<span class="op">=</span><span class="va">model_lm</span>,</span>
<span>                          balance_data<span class="op">=</span><span class="st">'no'</span>,</span>
<span>                          mode<span class="op">=</span><span class="st">'regression'</span>,</span>
<span>                          prop<span class="op">=</span><span class="fl">0.7</span>,</span>
<span>                          morans<span class="op">=</span><span class="cn">F</span>,</span>
<span>                          tune_grid_size<span class="op">=</span> <span class="fl">10</span>,</span>
<span>                          k<span class="op">=</span><span class="fl">10</span>,</span>
<span>                          racing<span class="op">=</span><span class="cn">F</span><span class="op">)</span> <span class="co">## Balanced data= up updamples and down downsampled to create a balanced set. For regression 'no' has to be selected.</span></span>
<span><span class="co">#&gt;   |                                                                              |                                                                      |   0%  |                                                                              |====                                                                  |   5%  |                                                                              |=======                                                               |  10%  |                                                                              |==========                                                            |  15%  |                                                                              |==============                                                        |  20%  |                                                                              |==================                                                    |  25%  |                                                                              |=====================                                                 |  30%  |                                                                              |========================                                              |  35%  |                                                                              |============================                                          |  40%  |                                                                              |================================                                      |  45%  |                                                                              |===================================                                   |  50%  |                                                                              |======================================                                |  55%  |                                                                              |==========================================                            |  60%  |                                                                              |==============================================                        |  65%  |                                                                              |=================================================                     |  70%  |                                                                              |====================================================                  |  75%  |                                                                              |========================================================              |  80%  |                                                                              |============================================================          |  85%  |                                                                              |===============================================================       |  90%  |                                                                              |==================================================================    |  95%  |                                                                              |======================================================================| 100%</span></span>
<span><span class="co">#racing can't be used for linear models - no parameters to tune</span></span>
<span></span>
<span><span class="co">#save(yhats, file='Regression_lm') #always a good idea</span></span></code></pre></div>
<p>Model performance can be examined the same way as in the
classification example, however the metrics are different. We provide
root mean square error (rmse) and R2. You can see that the overall R2 is
0.13 but there is substantial variation across loci in predictive
performance.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ModelPerf_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mrIMLperformance.html">mrIMLperformance</a></span><span class="op">(</span><span class="va">yhats_lm</span>,</span>
<span>                                 Model<span class="op">=</span><span class="va">model_lm</span>,</span>
<span>                                 Y<span class="op">=</span><span class="va">Y</span>,</span>
<span>                                 mode<span class="op">=</span><span class="st">'regression'</span><span class="op">)</span></span>
<span><span class="va">ModelPerf_lm</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="co">#predictive performance for individual responses. </span></span>
<span><span class="co">#&gt;              response model_name       rmse    rsquared</span></span>
<span><span class="co">#&gt; 1   CANDIDATE_GI5_108 linear_reg 0.06426578 0.021187687</span></span>
<span><span class="co">#&gt; 2   CANDIDATE_GI5_198 linear_reg 0.20118507 0.256330020</span></span>
<span><span class="co">#&gt; 3   CANDIDATE_GI5_268 linear_reg 0.09413783 0.001884908</span></span>
<span><span class="co">#&gt; 4    CANDIDATE_GI5_92 linear_reg 0.13117710 0.075625051</span></span>
<span><span class="co">#&gt; 5  CANDIDATE_GI5_1950 linear_reg 0.24207693 0.555279383</span></span>
<span><span class="co">#&gt; 6  CANDIDATE_GI5_2382 linear_reg 0.21693924 0.071970365</span></span>
<span><span class="co">#&gt; 7  CANDIDATE_GI5_2405 linear_reg 0.12739650 0.573200547</span></span>
<span><span class="co">#&gt; 8  CANDIDATE_GI5_2612 linear_reg 0.15119276 0.491409229</span></span>
<span><span class="co">#&gt; 9  CANDIDATE_GI5_2641 linear_reg 0.16484592 0.003718373</span></span>
<span><span class="co">#&gt; 10   CANDIDATE_GI5_33 linear_reg 0.13251763 0.549556034</span></span>
<span><span class="co">#&gt; 11 CANDIDATE_GI5_3966 linear_reg 0.27581779 0.001344843</span></span>
<span><span class="co">#&gt; 12 CANDIDATE_GI5_5033 linear_reg 0.07460969 0.164143944</span></span>
<span><span class="co">#&gt; 13 CANDIDATE_GI5_5090 linear_reg 0.15172275 0.207067832</span></span>
<span><span class="co">#&gt; 14 CANDIDATE_GI5_5119 linear_reg 0.16307676 0.000889029</span></span>
<span><span class="co">#&gt; 15 CANDIDATE_GI5_8997 linear_reg 0.12887369 0.578833028</span></span>
<span><span class="co">#&gt; 16 CANDIDATE_GI5_9287 linear_reg 0.15968264 0.083272899</span></span>
<span><span class="co">#&gt; 17 CANDIDATE_GI5_9447 linear_reg 0.17151250 0.028827830</span></span>
<span><span class="co">#&gt; 18 CANDIDATE_GI5_9551 linear_reg 0.16687285 0.424767550</span></span>
<span><span class="co">#&gt; 19 CANDIDATE_GI5_9585 linear_reg 0.15578584 0.599975713</span></span>
<span><span class="co">#&gt; 20 CANDIDATE_GI5_9659 linear_reg 0.12543953 0.573035761</span></span>
<span><span class="va">ModelPerf_lm</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="co">#overall average r2 </span></span>
<span><span class="co">#&gt; [1] 0.1549564</span></span></code></pre></div>
<p>Lets compare the performance of linear models to that of random
forests. Random forests is the computational engine in gradient forests.
Notice for random forests we have two hyperparameters to tune; mtry
(number of features to randomly include at each split) and min_n (the
minimum number of data points in a node that are required for the node
to be split further). The syntax ‘tune()’ acts a placeholder to tell
MrIML to tune those hyperparamters across a grid of values (defined in
MRIML predicts ‘tune_grid_size’ argument). Different algorithms will
have different hyperparameters.See <a href="https://www.tidymodels.org/find/parsnip/" class="external-link uri">https://www.tidymodels.org/find/parsnip/</a> for parameter
details. Note that large grid sizes (&gt;10) for algorithms with lots of
hyperparameters (such as extreme gradient boosting) will be
computationally demanding. In this case we choose a grid size of 5.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model_rf</span> <span class="op">&lt;-</span> <span class="fu">rand_forest</span><span class="op">(</span>trees <span class="op">=</span> <span class="fl">100</span>,</span>
<span>              mode <span class="op">=</span> <span class="st">"regression"</span>,</span>
<span>              mtry <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>,</span>
<span>              min_n <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="co">#100 trees are set for brevity. Aim to start with 1000</span></span>
<span>         <span class="fu">set_engine</span><span class="op">(</span><span class="st">"randomForest"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">yhats_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mrIMLpredicts.html">mrIMLpredicts</a></span><span class="op">(</span>X<span class="op">=</span><span class="va">X</span>,</span>
<span>                          Y<span class="op">=</span><span class="va">Y</span>,</span>
<span>                          Model<span class="op">=</span><span class="va">model_rf</span>,</span>
<span>                          balance_data<span class="op">=</span><span class="st">'no'</span>,</span>
<span>                          mode<span class="op">=</span><span class="st">'regression'</span>,</span>
<span>                          tune_grid_size<span class="op">=</span><span class="fl">5</span>,</span>
<span>                          seed <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample.int</a></span><span class="op">(</span><span class="fl">1e8</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;   |                                                                              |                                                                      |   0%  |                                                                              |====                                                                  |   5%  |                                                                              |=======                                                               |  10%  |                                                                              |==========                                                            |  15%  |                                                                              |==============                                                        |  20%  |                                                                              |==================                                                    |  25%  |                                                                              |=====================                                                 |  30%  |                                                                              |========================                                              |  35%  |                                                                              |============================                                          |  40%  |                                                                              |================================                                      |  45%  |                                                                              |===================================                                   |  50%  |                                                                              |======================================                                |  55%  |                                                                              |==========================================                            |  60%  |                                                                              |==============================================                        |  65%  |                                                                              |=================================================                     |  70%  |                                                                              |====================================================                  |  75%  |                                                                              |========================================================              |  80%  |                                                                              |============================================================          |  85%  |                                                                              |===============================================================       |  90%  |                                                                              |==================================================================    |  95%  |                                                                              |======================================================================| 100%</span></span>
<span></span>
<span><span class="co">#save(yhats, file='Regression_rf')</span></span>
<span></span>
<span><span class="va">ModelPerf_rf</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mrIMLperformance.html">mrIMLperformance</a></span><span class="op">(</span><span class="va">yhats_rf</span>,</span>
<span>                                 Model<span class="op">=</span><span class="va">model_rf</span>,</span>
<span>                                 <span class="va">Y</span>,</span>
<span>                                 mode<span class="op">=</span><span class="st">'regression'</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ModelPerf_rf</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="co">#predictive performance for individual responses. </span></span>
<span><span class="co">#&gt;              response  model_name       rmse    rsquared</span></span>
<span><span class="co">#&gt; 1   CANDIDATE_GI5_108 rand_forest 0.04090471 0.047682012</span></span>
<span><span class="co">#&gt; 2   CANDIDATE_GI5_198 rand_forest 0.12915210 0.598071204</span></span>
<span><span class="co">#&gt; 3   CANDIDATE_GI5_268 rand_forest 0.06664649 0.415936430</span></span>
<span><span class="co">#&gt; 4    CANDIDATE_GI5_92 rand_forest 0.08365576 0.076770963</span></span>
<span><span class="co">#&gt; 5  CANDIDATE_GI5_1950 rand_forest 0.12109386 0.617765960</span></span>
<span><span class="co">#&gt; 6  CANDIDATE_GI5_2382 rand_forest 0.11288976 0.111316554</span></span>
<span><span class="co">#&gt; 7  CANDIDATE_GI5_2405 rand_forest 0.13193547 0.535127395</span></span>
<span><span class="co">#&gt; 8  CANDIDATE_GI5_2612 rand_forest 0.13217971 0.608224408</span></span>
<span><span class="co">#&gt; 9  CANDIDATE_GI5_2641 rand_forest 0.08422936 0.005897323</span></span>
<span><span class="co">#&gt; 10   CANDIDATE_GI5_33 rand_forest 0.13399965 0.709763696</span></span>
<span><span class="co">#&gt; 11 CANDIDATE_GI5_3966 rand_forest 0.15185373 0.045949308</span></span>
<span><span class="co">#&gt; 12 CANDIDATE_GI5_5033 rand_forest 0.04755493 0.010344961</span></span>
<span><span class="co">#&gt; 13 CANDIDATE_GI5_5090 rand_forest 0.08205244 0.779996924</span></span>
<span><span class="co">#&gt; 14 CANDIDATE_GI5_5119 rand_forest 0.05939268 0.004521246</span></span>
<span><span class="co">#&gt; 15 CANDIDATE_GI5_8997 rand_forest 0.13711630 0.650710209</span></span>
<span><span class="co">#&gt; 16 CANDIDATE_GI5_9287 rand_forest 0.06407835 0.047821902</span></span>
<span><span class="co">#&gt; 17 CANDIDATE_GI5_9447 rand_forest 0.11846364 0.151671114</span></span>
<span><span class="co">#&gt; 18 CANDIDATE_GI5_9551 rand_forest 0.11316072 0.592370327</span></span>
<span><span class="co">#&gt; 19 CANDIDATE_GI5_9585 rand_forest 0.13721247 0.429543922</span></span>
<span><span class="co">#&gt; 20 CANDIDATE_GI5_9659 rand_forest 0.11037509 0.649462768</span></span>
<span><span class="va">ModelPerf_rf</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="co">#overall average r2 </span></span>
<span><span class="co">#&gt; [1] 0.1028974</span></span>
<span></span>
<span><span class="co">#easier to see with plots</span></span>
<span><span class="va">plots</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mrPerformancePlot.html">mrPerformancePlot</a></span><span class="op">(</span>ModelPerf1<span class="op">=</span><span class="va">ModelPerf_lm</span>,</span>
<span>                           ModelPerf2 <span class="op">=</span> <span class="va">ModelPerf_rf</span>,</span>
<span>                           mod_names<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">'linear_reg'</span>,<span class="st">'rand_forest'</span><span class="op">)</span>,</span>
<span>                           mode<span class="op">=</span><span class="st">'regression'</span> <span class="op">)</span> </span>
<span></span>
<span><span class="va">plots</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></span></code></pre></div>
<p><img src="Regression_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">plots</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span></span></code></pre></div>
<p><img src="Regression_files/figure-html/unnamed-chunk-4-2.png" width="768" style="display: block; margin: auto;">
## Plotting</p>
<p>You can see that predictive performance is actually slightly less
using random forests (overall R2 = 0.12) but for some loci random
forests does better than our linear models and sometimes worse. Which to
choose? Generally simpler models are preferred (the linear model in this
case) but it depends on how important to think non-linear response are.
In future versions of MrIML we will implement ensemble models that will
overcome this issue. For the time-being we will have a look at variable
importance for the random forest based model.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">VI</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mrVip.html">mrvip</a></span><span class="op">(</span>yhats<span class="op">=</span><span class="va">yhats_rf</span>,</span>
<span>            mrBootstrap_obj <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>            X<span class="op">=</span><span class="va">X</span>,</span>
<span>            Y<span class="op">=</span><span class="va">Y</span>,</span>
<span>            mode<span class="op">=</span><span class="st">'regression'</span>,</span>
<span>            threshold <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span>            global_top_var <span class="op">=</span> <span class="fl">10</span>,</span>
<span>            local_top_var <span class="op">=</span> <span class="fl">5</span>,</span>
<span>            taxa<span class="op">=</span><span class="st">'CANDIDATE_GI5_9585'</span>,</span>
<span>            ModelPerf<span class="op">=</span><span class="va">ModelPerf_rf</span><span class="op">)</span> </span>
<span><span class="co">#&gt; [1] "here"</span></span>
<span></span>
<span><span class="va">VI</span><span class="op">[[</span><span class="fl">3</span><span class="op">]</span><span class="op">]</span> <span class="co">#Importance plot</span></span></code></pre></div>
<p><img src="Regression_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">VI</span><span class="op">[[</span><span class="fl">4</span><span class="op">]</span><span class="op">]</span> <span class="co">#PCA</span></span></code></pre></div>
<p><img src="Regression_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;">
Cutoff reduces the number of individual SNP plots presented in the
second plot and ‘plot.pca=’yes’’ enables the variable importance scores
to be analysed using principal component analysis (PCA) where SNPs
closer in PCA space are shaped by similar combinations of features. You
can see that bio_18 (summer precipitation), bio_1 (mean annual
temperature) and bio_10 (mean summer temperature) are the most important
features overall. Summer precipitation was not as important in
Fitzpatrick et al but otherwise these results are similar. The second
plot shows the individual models (with an r2 &gt; 0.1, for your data you
will need to play around with this threshold) and you can see for some
SNPs bio_1 is more important whereas for another MEM.1 is more
prominent.The PCA shows that candidate 5119, 9287, 5033 and 108 are
shaped similarly by the features we included and may, for example, be
product of linked selection.</p>
<p>Note that you can also calculate bootstraps for importance scores
(and partial dependencies), but this functionality is still under
development for regression models.</p>
<p>Now we can explore the model further my plotting the relationships
between our SNPs and a feature in our set. Lets choose bio_1 (mean
annual temperature) and plot the individual and global (average of all
SNPs) partial dependency (PD) plots.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">flashlightObj</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mrFlashlight.html">mrFlashlight</a></span><span class="op">(</span>yhats<span class="op">=</span><span class="va">yhats_rf</span>,</span>
<span>                              X<span class="op">=</span><span class="va">X</span>,</span>
<span>                              Y<span class="op">=</span><span class="va">Y</span>,</span>
<span>                              response <span class="op">=</span> <span class="st">"multi"</span>,</span>
<span>                              mode<span class="op">=</span><span class="st">"regression"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">profileData_pd</span> <span class="op">&lt;-</span> <span class="fu">light_profile</span><span class="op">(</span><span class="va">flashlightObj</span>,</span>
<span>                                v <span class="op">=</span> <span class="st">"bio_1"</span><span class="op">)</span> <span class="co">#partial dependencies</span></span>
<span></span>
<span><span class="fu"><a href="../reference/mrProfileplot.html">mrProfileplot</a></span><span class="op">(</span><span class="va">profileData_pd</span>,</span>
<span>              sdthresh <span class="op">=</span><span class="fl">0.01</span><span class="op">)</span></span></code></pre></div>
<p><img src="Regression_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;"></p>
<pre><code><span><span class="co">#&gt;  Press [enter] to continue to the global summary plot</span></span>
<span><span class="co">#&gt; `geom_smooth()` using formula = 'y ~ x'</span></span></code></pre>
<p><img src="Regression_files/figure-html/unnamed-chunk-6-2.png" width="768" style="display: block; margin: auto;">
The first plot is a partial dependency for all SNPs that respond to mean
annual temperature. What we mean by respond here is that the prediction
surface (the line) deviates across the Y axis of the PD plots. We
measure this deviation by calculating the standard deviation and use
that as a threshold (‘sd thresh=0.01’ in this case and this will differ
by data set) to ease visualization of these relationships. The second
plot is the smoothed average partial dependency of SNPs across a annual
temperature gradient. This is very similar to the pattern observed by
Fitzpatrick et al except with a slight decline in SNP turnover with mean
annual temperatures &gt; 0. Combined,you can see here only few candidate
SNPs are driving this pattern and these may warrant further
interrogation.</p>
<p>Lets compare the PDs to accumulated local effect plots that are less
sensitive to correlations among features (see Molnar 2019).</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">profileData_ale</span> <span class="op">&lt;-</span> <span class="fu">light_profile</span><span class="op">(</span><span class="va">flashlightObj</span>,</span>
<span>                                 v <span class="op">=</span> <span class="st">"bio_1"</span>,</span>
<span>                                 type <span class="op">=</span> <span class="st">"ale"</span><span class="op">)</span> <span class="co">#accumulated local effects</span></span>
<span></span>
<span><span class="fu"><a href="../reference/mrProfileplot.html">mrProfileplot</a></span><span class="op">(</span><span class="va">profileData_ale</span>,</span>
<span>              sdthresh <span class="op">=</span><span class="fl">0.01</span><span class="op">)</span></span></code></pre></div>
<p><img src="Regression_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;"></p>
<pre><code><span><span class="co">#&gt;  Press [enter] to continue to the global summary plot</span></span>
<span><span class="co">#&gt; `geom_smooth()` using formula = 'y ~ x'</span></span></code></pre>
<p><img src="Regression_files/figure-html/unnamed-chunk-7-2.png" width="768" style="display: block; margin: auto;">
The effect of mean annual temperature on SNP turnover is not as distinct
in the global ALE plot. This may mean that correlations between features
may be important for the predictions.</p>
<p>MrIML has easy to use functionality that can can quantify
interactions between features. Note that this can take a while to
compute and will be the topic of a future work.</p>
<p>This is touching only the surface of what is possible in terms of
interrogating this model. Both Flashlight and IML packages have a wide
variety of tools that can offer novel insights into how these models
perform. See <a href="https://cran.r-project.org/web/packages/flashlight/vignettes/flashlight.html" class="external-link uri">https://cran.r-project.org/web/packages/flashlight/vignettes/flashlight.html</a>
and <a href="https://cran.r-project.org/web/packages/iml/vignettes/intro.html" class="external-link uri">https://cran.r-project.org/web/packages/iml/vignettes/intro.html</a>
for other options.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by <a href="https://discover.utas.edu.au/Nick.FountainJones" class="external-link">Nick Fountain-Jone</a>, <a href="https://machado-lab.github.io/" class="external-link">Gustavo Machado</a>, Chris Kozakiewicz, Nick Clark.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

      </footer>
</div>






  </body>
</html>
